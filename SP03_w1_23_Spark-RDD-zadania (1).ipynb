{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f4571f9-9ecb-47a9-80cc-dfa10e34f79d",
   "metadata": {},
   "source": [
    "# Wprowadzenie \n",
    "Nasze wyzwanie jest z jednej strony proste, z drugiej strony dość ambitne. \n",
    "\n",
    "Jedno z klasycznych \"Hello World\" świata Big Data polega na zliczaniu wystąpienia słów. Dane wejściowe - plik tekstowy lub strumień tekstu. Dane wynikowe - liczba wystąpień każdego ze słów. Klasyka. \n",
    "\n",
    "My zrobimy to samo, jednak naszymi danymi wejściowymi będą... opowiadania Artura Conan Doyla (czyli standard), ale nie w plikach tekstowych, a w formacie PDF (i to już standard nie jest). \n",
    "\n",
    "Trudne? Nic bardziej mylnego. Python to mnogość bibliotek o niezliczonej funkcjonalności. \n",
    "\n",
    "Prosty przykład...\n",
    "\n",
    "Pobierz nasze dane wejściowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df35a83a-8a0b-4fa7-984e-529ab3653a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7830123"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://jankiewicz.pl/bigdata/bigdata-sp/cano-pdf.zip\", allow_redirects=True)\n",
    "open('cano-pdf.zip', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05426d19-d5c6-40b0-b988-7963199385fb",
   "metadata": {},
   "source": [
    "Rozpakuj nasz plik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858b95c6-e308-4c6b-a22d-a54da542dd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Archive:  cano-pdf.zip\n  inflating: cano-pdf/3gab.pdf       \n  inflating: cano-pdf/3gar.pdf       \n  inflating: cano-pdf/3stu.pdf       \n  inflating: cano-pdf/abbe.pdf       \n  inflating: cano-pdf/bery.pdf       \n  inflating: cano-pdf/blac.pdf       \n  inflating: cano-pdf/blan.pdf       \n  inflating: cano-pdf/blue.pdf       \n  inflating: cano-pdf/bosc.pdf       \n  inflating: cano-pdf/bruc.pdf       \n  inflating: cano-pdf/card.pdf       \n  inflating: cano-pdf/chas.pdf       \n  inflating: cano-pdf/copp.pdf       \n  inflating: cano-pdf/cree.pdf       \n  inflating: cano-pdf/croo.pdf       \n  inflating: cano-pdf/danc.pdf       \n  inflating: cano-pdf/devi.pdf       \n  inflating: cano-pdf/dyin.pdf       \n  inflating: cano-pdf/empt.pdf       \n  inflating: cano-pdf/engr.pdf       \n  inflating: cano-pdf/fina.pdf       \n  inflating: cano-pdf/five.pdf       \n  inflating: cano-pdf/glor.pdf       \n  inflating: cano-pdf/gold.pdf       \n  inflating: cano-pdf/gree.pdf       \n  inflating: cano-pdf/houn.pdf       \n  inflating: cano-pdf/iden.pdf       \n  inflating: cano-pdf/illu.pdf       \n  inflating: cano-pdf/lady.pdf       \n  inflating: cano-pdf/last.pdf       \n  inflating: cano-pdf/lion.pdf       \n  inflating: cano-pdf/maza.pdf       \n  inflating: cano-pdf/miss.pdf       \n  inflating: cano-pdf/musg.pdf       \n  inflating: cano-pdf/nava.pdf       \n  inflating: cano-pdf/nobl.pdf       \n  inflating: cano-pdf/norw.pdf       \n  inflating: cano-pdf/prio.pdf       \n  inflating: cano-pdf/redc.pdf       \n  inflating: cano-pdf/redh.pdf       \n  inflating: cano-pdf/reig.pdf       \n  inflating: cano-pdf/resi.pdf       \n  inflating: cano-pdf/reti.pdf       \n  inflating: cano-pdf/scan.pdf       \n  inflating: cano-pdf/seco.pdf       \n  inflating: cano-pdf/shos.pdf       \n  inflating: cano-pdf/sign.pdf       \n  inflating: cano-pdf/silv.pdf       \n  inflating: cano-pdf/sixn.pdf       \n  inflating: cano-pdf/soli.pdf       \n  inflating: cano-pdf/spec.pdf       \n  inflating: cano-pdf/stoc.pdf       \n  inflating: cano-pdf/stud.pdf       \n  inflating: cano-pdf/suss.pdf       \n  inflating: cano-pdf/thor.pdf       \n  inflating: cano-pdf/twis.pdf       \n  inflating: cano-pdf/vall.pdf       \n  inflating: cano-pdf/veil.pdf       \n  inflating: cano-pdf/wist.pdf       \n  inflating: cano-pdf/yell.pdf       \n"
    }
   ],
   "source": [
    "%%sh\n",
    "unzip cano-pdf.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101379f2-153d-4dc0-93cc-87076cafe39a",
   "metadata": {},
   "source": [
    "Sprawdź czy mamy zainstalowany potrzebny moduł"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952b16c-623b-4ecf-a467-8730ef53e46c",
   "metadata": {},
   "source": [
    "# PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76b6b8e-e402-4630-95c1-ebe94559e6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "PyPDF2==3.0.1\n"
    }
   ],
   "source": [
    "%%sh\n",
    "pip freeze | grep PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de31298-a69d-4aaf-b1ed-92ff1c4f868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10\n"
    }
   ],
   "source": [
    "import PyPDF2 \n",
    "    \n",
    "# Utwórz obiekt odnoszący się do przykładowego pliku\n",
    "pdfFileObj = open('cano-pdf/3gab.pdf', 'rb') \n",
    "    \n",
    "# Utwórz obiekt PdfFileReader \n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj) \n",
    "    \n",
    "# To wszystko \n",
    "# Zobacz ile ten plik ma stron \n",
    "print(len(pdfReader.pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac0b79f-a329-46b0-b5f7-a89b14510b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The Adventure of the Three Gables\nArthur Conan Doyle\n"
    }
   ],
   "source": [
    "# Pobierz pierwszą ze stron\n",
    "pageObj = pdfReader.pages[0]\n",
    "    \n",
    "# Dokonaj esktrakcji tekstu, który się na niej znajduje \n",
    "print(pageObj.extract_text()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e462d76a-135c-4efa-b5fb-7f9d93aea88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nie zapomnij zamknąć nasz obiekt pliku\n",
    "pdfFileObj.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db0993-26d0-47f6-a84d-a27c5a795487",
   "metadata": {},
   "source": [
    "Proste prawda? \n",
    "\n",
    "No to do roboty. W pierwszej kolejności załadujmy dane tam, gdzie będą one mogły być wydajnie odczytywane przez wiele węzłów klastra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e10fb-c6ff-408b-9a85-ce1ecd68c40e",
   "metadata": {},
   "source": [
    "# Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d816c2-f589-45a6-bbb0-ccb108a8fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "hadoop fs -mkdir -p cano-pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1342456-64b1-4f6c-86b4-a406ee46f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "hadoop fs -put -f cano-pdf/* cano-pdf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f449e47f-37a7-434d-80a4-537b00a9dae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 60 items\n-rw-r--r--   2 root hadoop      92929 2023-11-30 12:58 cano-pdf/3gab.pdf\n-rw-r--r--   2 root hadoop      85278 2023-11-30 12:58 cano-pdf/3gar.pdf\n-rw-r--r--   2 root hadoop      82246 2023-11-30 12:58 cano-pdf/3stu.pdf\n-rw-r--r--   2 root hadoop     105053 2023-11-30 12:58 cano-pdf/abbe.pdf\n-rw-r--r--   2 root hadoop     105315 2023-11-30 12:58 cano-pdf/bery.pdf\n-rw-r--r--   2 root hadoop      94016 2023-11-30 12:58 cano-pdf/blac.pdf\n-rw-r--r--   2 root hadoop      94094 2023-11-30 12:58 cano-pdf/blan.pdf\n-rw-r--r--   2 root hadoop     103941 2023-11-30 12:58 cano-pdf/blue.pdf\n-rw-r--r--   2 root hadoop     115124 2023-11-30 12:58 cano-pdf/bosc.pdf\n-rw-r--r--   2 root hadoop     115501 2023-11-30 12:58 cano-pdf/bruc.pdf\n-rw-r--r--   2 root hadoop     106359 2023-11-30 12:58 cano-pdf/card.pdf\n-rw-r--r--   2 root hadoop      89194 2023-11-30 12:58 cano-pdf/chas.pdf\n-rw-r--r--   2 root hadoop     111383 2023-11-30 12:58 cano-pdf/copp.pdf\n-rw-r--r--   2 root hadoop      87831 2023-11-30 12:58 cano-pdf/cree.pdf\n-rw-r--r--   2 root hadoop      78558 2023-11-30 12:58 cano-pdf/croo.pdf\n-rw-r--r--   2 root hadoop     289443 2023-11-30 12:58 cano-pdf/danc.pdf\n-rw-r--r--   2 root hadoop     103336 2023-11-30 12:58 cano-pdf/devi.pdf\n-rw-r--r--   2 root hadoop      80189 2023-11-30 12:58 cano-pdf/dyin.pdf\n-rw-r--r--   2 root hadoop     102150 2023-11-30 12:58 cano-pdf/empt.pdf\n-rw-r--r--   2 root hadoop     101328 2023-11-30 12:58 cano-pdf/engr.pdf\n-rw-r--r--   2 root hadoop      92842 2023-11-30 12:58 cano-pdf/fina.pdf\n-rw-r--r--   2 root hadoop     103239 2023-11-30 12:58 cano-pdf/five.pdf\n-rw-r--r--   2 root hadoop     101743 2023-11-30 12:58 cano-pdf/glor.pdf\n-rw-r--r--   2 root hadoop     235338 2023-11-30 12:58 cano-pdf/gold.pdf\n-rw-r--r--   2 root hadoop      99901 2023-11-30 12:58 cano-pdf/gree.pdf\n-rw-r--r--   2 root hadoop     428821 2023-11-30 12:58 cano-pdf/houn.pdf\n-rw-r--r--   2 root hadoop      89917 2023-11-30 12:58 cano-pdf/iden.pdf\n-rw-r--r--   2 root hadoop     113311 2023-11-30 12:58 cano-pdf/illu.pdf\n-rw-r--r--   2 root hadoop      95089 2023-11-30 12:58 cano-pdf/lady.pdf\n-rw-r--r--   2 root hadoop      88002 2023-11-30 12:58 cano-pdf/last.pdf\n-rw-r--r--   2 root hadoop      94999 2023-11-30 12:58 cano-pdf/lion.pdf\n-rw-r--r--   2 root hadoop      78598 2023-11-30 12:58 cano-pdf/maza.pdf\n-rw-r--r--   2 root hadoop     142274 2023-11-30 12:58 cano-pdf/miss.pdf\n-rw-r--r--   2 root hadoop      88564 2023-11-30 12:58 cano-pdf/musg.pdf\n-rw-r--r--   2 root hadoop     251235 2023-11-30 12:58 cano-pdf/nava.pdf\n-rw-r--r--   2 root hadoop     107197 2023-11-30 12:58 cano-pdf/nobl.pdf\n-rw-r--r--   2 root hadoop     113865 2023-11-30 12:58 cano-pdf/norw.pdf\n-rw-r--r--   2 root hadoop     288676 2023-11-30 12:58 cano-pdf/prio.pdf\n-rw-r--r--   2 root hadoop     106230 2023-11-30 12:58 cano-pdf/redc.pdf\n-rw-r--r--   2 root hadoop     110971 2023-11-30 12:58 cano-pdf/redh.pdf\n-rw-r--r--   2 root hadoop     278830 2023-11-30 12:58 cano-pdf/reig.pdf\n-rw-r--r--   2 root hadoop      86744 2023-11-30 12:58 cano-pdf/resi.pdf\n-rw-r--r--   2 root hadoop      86580 2023-11-30 12:58 cano-pdf/reti.pdf\n-rw-r--r--   2 root hadoop     110035 2023-11-30 12:58 cano-pdf/scan.pdf\n-rw-r--r--   2 root hadoop     116305 2023-11-30 12:58 cano-pdf/seco.pdf\n-rw-r--r--   2 root hadoop      75111 2023-11-30 12:58 cano-pdf/shos.pdf\n-rw-r--r--   2 root hadoop     332570 2023-11-30 12:58 cano-pdf/sign.pdf\n-rw-r--r--   2 root hadoop     103086 2023-11-30 12:58 cano-pdf/silv.pdf\n-rw-r--r--   2 root hadoop     102480 2023-11-30 12:58 cano-pdf/sixn.pdf\n-rw-r--r--   2 root hadoop      96460 2023-11-30 12:58 cano-pdf/soli.pdf\n-rw-r--r--   2 root hadoop     102616 2023-11-30 12:58 cano-pdf/spec.pdf\n-rw-r--r--   2 root hadoop      97570 2023-11-30 12:58 cano-pdf/stoc.pdf\n-rw-r--r--   2 root hadoop     341888 2023-11-30 12:58 cano-pdf/stud.pdf\n-rw-r--r--   2 root hadoop      84823 2023-11-30 12:58 cano-pdf/suss.pdf\n-rw-r--r--   2 root hadoop     107724 2023-11-30 12:58 cano-pdf/thor.pdf\n-rw-r--r--   2 root hadoop     100493 2023-11-30 12:58 cano-pdf/twis.pdf\n-rw-r--r--   2 root hadoop     423146 2023-11-30 12:58 cano-pdf/vall.pdf\n-rw-r--r--   2 root hadoop      64287 2023-11-30 12:58 cano-pdf/veil.pdf\n-rw-r--r--   2 root hadoop     136764 2023-11-30 12:58 cano-pdf/wist.pdf\n-rw-r--r--   2 root hadoop      82517 2023-11-30 12:58 cano-pdf/yell.pdf\n"
    }
   ],
   "source": [
    "%%sh\n",
    "hadoop fs -ls cano-pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572fa9f6-961c-4e5f-a5ce-89ffb853d518",
   "metadata": {},
   "source": [
    "Utwórzmy teraz nasz obiekt konteksu (o ile jeszcze nie istnieje)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5181207-51cd-4dab-88cb-b8e7b099307c",
   "metadata": {},
   "source": [
    "# Utworzenie obiektu kontekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f135a0-8ad0-4fca-b8f0-4a28618b96ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w przypadku korzystania z kernela Python\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4309310c-8d6f-4a0b-9c23-c58a429bbc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n23/11/30 12:58:39 INFO SparkEnv: Registering MapOutputTracker\n23/11/30 12:58:39 INFO SparkEnv: Registering BlockManagerMaster\n23/11/30 12:58:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n23/11/30 12:58:39 INFO SparkEnv: Registering OutputCommitCoordinator\n"
    }
   ],
   "source": [
    "# w przypadku korzystania z kernela Python\n",
    "conf = SparkConf().setAppName(\"Spark - RDD - warsztaty\").setMaster(\"yarn\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b935a51-a15d-47a8-b1b2-92000e959b04",
   "metadata": {},
   "source": [
    "Do tej pory szło gładko. Teraz mamy mały problem. <br> \n",
    "W jaki sposób zaczytać nasze pliki? \n",
    "\n",
    "Nie są to pliki tekstowe, więc `textFile` prowadzający dane linia po linii do naszych dokumentów nie jest tu przydatny.<br>\n",
    "Zaglądnij na https://spark.apache.org/docs/latest/rdd-programming-guide.html#external-datasets\n",
    "\n",
    "Właściwie, żadna z metod nie jest tu odpowiednia. \n",
    "\n",
    "Zrobimy zatem tak, naszymi danymi wejściowymi nie będą pliki. Będą ich nazwy, a Spark na podstawie tych nazw będzie je odczytywał i ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d982113f-449e-47a1-8683-c4a5c564673c",
   "metadata": {},
   "source": [
    "# Przygotowanie metadanych wejściowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "475f5203-8800-4a13-a028-34d9a0fa3cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://pbd-cluster-m.europe-west4-c.c.big-data-10-2023-kw.internal:36137\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Spark - RDD - warsztaty</code></dd>\n            </dl>\n        </div>\n        ",
      "text/plain": "<SparkContext master=yarn appName=Spark - RDD - warsztaty>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f3b8f04-4e23-4010-8251-7dd4e33c89c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "hadoop fs -ls cano-pdf > files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d1dc76f-816c-45d5-a26d-e6007504742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "hadoop fs -copyFromLocal files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41cdb297-e0ea-470b-99b0-b28dc669b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawFiles = sc.textFile(\"files.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ad6455f-aa69-4b55-9290-3bff03afbe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "                                                                                \r"
    },
    {
     "data": {
      "text/plain": "['Found 60 items',\n '-rw-r--r--   2 root hadoop      92929 2023-11-30 12:58 cano-pdf/3gab.pdf',\n '-rw-r--r--   2 root hadoop      85278 2023-11-30 12:58 cano-pdf/3gar.pdf',\n '-rw-r--r--   2 root hadoop      82246 2023-11-30 12:58 cano-pdf/3stu.pdf',\n '-rw-r--r--   2 root hadoop     105053 2023-11-30 12:58 cano-pdf/abbe.pdf',\n '-rw-r--r--   2 root hadoop     105315 2023-11-30 12:58 cano-pdf/bery.pdf',\n '-rw-r--r--   2 root hadoop      94016 2023-11-30 12:58 cano-pdf/blac.pdf',\n '-rw-r--r--   2 root hadoop      94094 2023-11-30 12:58 cano-pdf/blan.pdf',\n '-rw-r--r--   2 root hadoop     103941 2023-11-30 12:58 cano-pdf/blue.pdf',\n '-rw-r--r--   2 root hadoop     115124 2023-11-30 12:58 cano-pdf/bosc.pdf',\n '-rw-r--r--   2 root hadoop     115501 2023-11-30 12:58 cano-pdf/bruc.pdf',\n '-rw-r--r--   2 root hadoop     106359 2023-11-30 12:58 cano-pdf/card.pdf',\n '-rw-r--r--   2 root hadoop      89194 2023-11-30 12:58 cano-pdf/chas.pdf',\n '-rw-r--r--   2 root hadoop     111383 2023-11-30 12:58 cano-pdf/copp.pdf',\n '-rw-r--r--   2 root hadoop      87831 2023-11-30 12:58 cano-pdf/cree.pdf',\n '-rw-r--r--   2 root hadoop      78558 2023-11-30 12:58 cano-pdf/croo.pdf',\n '-rw-r--r--   2 root hadoop     289443 2023-11-30 12:58 cano-pdf/danc.pdf',\n '-rw-r--r--   2 root hadoop     103336 2023-11-30 12:58 cano-pdf/devi.pdf',\n '-rw-r--r--   2 root hadoop      80189 2023-11-30 12:58 cano-pdf/dyin.pdf',\n '-rw-r--r--   2 root hadoop     102150 2023-11-30 12:58 cano-pdf/empt.pdf',\n '-rw-r--r--   2 root hadoop     101328 2023-11-30 12:58 cano-pdf/engr.pdf',\n '-rw-r--r--   2 root hadoop      92842 2023-11-30 12:58 cano-pdf/fina.pdf',\n '-rw-r--r--   2 root hadoop     103239 2023-11-30 12:58 cano-pdf/five.pdf',\n '-rw-r--r--   2 root hadoop     101743 2023-11-30 12:58 cano-pdf/glor.pdf',\n '-rw-r--r--   2 root hadoop     235338 2023-11-30 12:58 cano-pdf/gold.pdf',\n '-rw-r--r--   2 root hadoop      99901 2023-11-30 12:58 cano-pdf/gree.pdf',\n '-rw-r--r--   2 root hadoop     428821 2023-11-30 12:58 cano-pdf/houn.pdf',\n '-rw-r--r--   2 root hadoop      89917 2023-11-30 12:58 cano-pdf/iden.pdf',\n '-rw-r--r--   2 root hadoop     113311 2023-11-30 12:58 cano-pdf/illu.pdf',\n '-rw-r--r--   2 root hadoop      95089 2023-11-30 12:58 cano-pdf/lady.pdf',\n '-rw-r--r--   2 root hadoop      88002 2023-11-30 12:58 cano-pdf/last.pdf',\n '-rw-r--r--   2 root hadoop      94999 2023-11-30 12:58 cano-pdf/lion.pdf',\n '-rw-r--r--   2 root hadoop      78598 2023-11-30 12:58 cano-pdf/maza.pdf',\n '-rw-r--r--   2 root hadoop     142274 2023-11-30 12:58 cano-pdf/miss.pdf',\n '-rw-r--r--   2 root hadoop      88564 2023-11-30 12:58 cano-pdf/musg.pdf',\n '-rw-r--r--   2 root hadoop     251235 2023-11-30 12:58 cano-pdf/nava.pdf',\n '-rw-r--r--   2 root hadoop     107197 2023-11-30 12:58 cano-pdf/nobl.pdf',\n '-rw-r--r--   2 root hadoop     113865 2023-11-30 12:58 cano-pdf/norw.pdf',\n '-rw-r--r--   2 root hadoop     288676 2023-11-30 12:58 cano-pdf/prio.pdf',\n '-rw-r--r--   2 root hadoop     106230 2023-11-30 12:58 cano-pdf/redc.pdf',\n '-rw-r--r--   2 root hadoop     110971 2023-11-30 12:58 cano-pdf/redh.pdf',\n '-rw-r--r--   2 root hadoop     278830 2023-11-30 12:58 cano-pdf/reig.pdf',\n '-rw-r--r--   2 root hadoop      86744 2023-11-30 12:58 cano-pdf/resi.pdf',\n '-rw-r--r--   2 root hadoop      86580 2023-11-30 12:58 cano-pdf/reti.pdf',\n '-rw-r--r--   2 root hadoop     110035 2023-11-30 12:58 cano-pdf/scan.pdf',\n '-rw-r--r--   2 root hadoop     116305 2023-11-30 12:58 cano-pdf/seco.pdf',\n '-rw-r--r--   2 root hadoop      75111 2023-11-30 12:58 cano-pdf/shos.pdf',\n '-rw-r--r--   2 root hadoop     332570 2023-11-30 12:58 cano-pdf/sign.pdf',\n '-rw-r--r--   2 root hadoop     103086 2023-11-30 12:58 cano-pdf/silv.pdf',\n '-rw-r--r--   2 root hadoop     102480 2023-11-30 12:58 cano-pdf/sixn.pdf',\n '-rw-r--r--   2 root hadoop      96460 2023-11-30 12:58 cano-pdf/soli.pdf',\n '-rw-r--r--   2 root hadoop     102616 2023-11-30 12:58 cano-pdf/spec.pdf',\n '-rw-r--r--   2 root hadoop      97570 2023-11-30 12:58 cano-pdf/stoc.pdf',\n '-rw-r--r--   2 root hadoop     341888 2023-11-30 12:58 cano-pdf/stud.pdf',\n '-rw-r--r--   2 root hadoop      84823 2023-11-30 12:58 cano-pdf/suss.pdf',\n '-rw-r--r--   2 root hadoop     107724 2023-11-30 12:58 cano-pdf/thor.pdf',\n '-rw-r--r--   2 root hadoop     100493 2023-11-30 12:58 cano-pdf/twis.pdf',\n '-rw-r--r--   2 root hadoop     423146 2023-11-30 12:58 cano-pdf/vall.pdf',\n '-rw-r--r--   2 root hadoop      64287 2023-11-30 12:58 cano-pdf/veil.pdf',\n '-rw-r--r--   2 root hadoop     136764 2023-11-30 12:58 cano-pdf/wist.pdf',\n '-rw-r--r--   2 root hadoop      82517 2023-11-30 12:58 cano-pdf/yell.pdf']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawFiles.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f2c12-6d2c-4f31-918f-899def8029f2",
   "metadata": {},
   "source": [
    "Jesteśmy zainteresowani tylko nazwami plików, a zatem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bc7b745-bf7f-4b3c-b0e1-8f1d29e9db42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "                                                                                \r"
    },
    {
     "data": {
      "text/plain": "['cano-pdf/3gab.pdf',\n 'cano-pdf/3gar.pdf',\n 'cano-pdf/3stu.pdf',\n 'cano-pdf/abbe.pdf',\n 'cano-pdf/bery.pdf',\n 'cano-pdf/blac.pdf',\n 'cano-pdf/blan.pdf',\n 'cano-pdf/blue.pdf',\n 'cano-pdf/bosc.pdf',\n 'cano-pdf/bruc.pdf',\n 'cano-pdf/card.pdf',\n 'cano-pdf/chas.pdf',\n 'cano-pdf/copp.pdf',\n 'cano-pdf/cree.pdf',\n 'cano-pdf/croo.pdf',\n 'cano-pdf/danc.pdf',\n 'cano-pdf/devi.pdf',\n 'cano-pdf/dyin.pdf',\n 'cano-pdf/empt.pdf',\n 'cano-pdf/engr.pdf',\n 'cano-pdf/fina.pdf',\n 'cano-pdf/five.pdf',\n 'cano-pdf/glor.pdf',\n 'cano-pdf/gold.pdf',\n 'cano-pdf/gree.pdf',\n 'cano-pdf/houn.pdf',\n 'cano-pdf/iden.pdf',\n 'cano-pdf/illu.pdf',\n 'cano-pdf/lady.pdf',\n 'cano-pdf/last.pdf',\n 'cano-pdf/lion.pdf',\n 'cano-pdf/maza.pdf',\n 'cano-pdf/miss.pdf',\n 'cano-pdf/musg.pdf',\n 'cano-pdf/nava.pdf',\n 'cano-pdf/nobl.pdf',\n 'cano-pdf/norw.pdf',\n 'cano-pdf/prio.pdf',\n 'cano-pdf/redc.pdf',\n 'cano-pdf/redh.pdf',\n 'cano-pdf/reig.pdf',\n 'cano-pdf/resi.pdf',\n 'cano-pdf/reti.pdf',\n 'cano-pdf/scan.pdf',\n 'cano-pdf/seco.pdf',\n 'cano-pdf/shos.pdf',\n 'cano-pdf/sign.pdf',\n 'cano-pdf/silv.pdf',\n 'cano-pdf/sixn.pdf',\n 'cano-pdf/soli.pdf',\n 'cano-pdf/spec.pdf',\n 'cano-pdf/stoc.pdf',\n 'cano-pdf/stud.pdf',\n 'cano-pdf/suss.pdf',\n 'cano-pdf/thor.pdf',\n 'cano-pdf/twis.pdf',\n 'cano-pdf/vall.pdf',\n 'cano-pdf/veil.pdf',\n 'cano-pdf/wist.pdf',\n 'cano-pdf/yell.pdf']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "rawFiles.filter(lambda s: \"cano\" in s).map(lambda s: re.search(\".* (\\S*)$\",s).group(1)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6920061-6985-4c9b-ae21-2b5a8c61b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = rawFiles.filter(lambda s: \"cano\" in s).map(lambda s: re.search(\".* (\\S*)$\",s).group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f987a-7898-41b8-a1e8-16eb3873f151",
   "metadata": {},
   "source": [
    "Nie chcemy aby całą ekstrakcję danych tekstowych z plików PDF wykonywał jeden węzeł. Sprawdźmy ile mamy partycji naszego RDD. \n",
    "\n",
    "Jeśli będzie ich zbyt mało, możemy zmienić ich liczbę za pomoca metody `repartition(liczba_partycji)`.\n",
    "\n",
    "Przeanalizuj to ile zasobów ma nasz klaster, w szczególności zwróć uwagę na liczbę procesorów we wszystkich maszynach.\n",
    "\n",
    "Stosując *regułę kciuka* ustaw liczbę partycji na taką, która jest równa liczbie procesorów. Wprowadź zmiany w powyższej linii, tak aby poniższa potwierdziła oczekiwaną liczbę partycji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa4e1588-3eb6-4112-9c06-8e25941ea4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileNames.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1faa2-45fb-47a7-aa07-0950f8d7c041",
   "metadata": {},
   "source": [
    "# Konwersja metadanych na dane \n",
    "\n",
    "Jeśli liczba partycji jest już w porządku, to czas na kluczowy moment. <br>\n",
    "Chcemy, aby każdy z elementów naszego RDD zamienił się z nazwy pliku, na szereg elementów odnoszących się do poszczególnych linii zawartych w tym pliku. \n",
    "\n",
    "Potrzebujemy zatem funkcji, która:\n",
    "* odczyta plik o podanej nazwie \n",
    "* dokona ekstracji jego zawartości\n",
    "* utworzy listę zawierającą poszczególne linie\n",
    "\n",
    "Funkcję tą wykorzystamy następnie w metodzie `flatMap` na naszym `RDD`. <br>\n",
    "Reszta będzie *easy peasy*. \n",
    "\n",
    "**Uwaga!** <br>\n",
    "Plik nie będzie znajdował się w lokalnym systemie plików węzła roboczego... będzie znajdował się w systemie plików HDFS!\n",
    "\n",
    "Aby sobie z tym poradzić, sprawdźmy czy mamy dostępną jeszcze jedną bibliotekę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9076d4aa-6bdc-45b4-98fb-184ec99ee84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "pydoop==2.0.0\n"
    }
   ],
   "source": [
    "%%sh\n",
    "pip freeze | grep pydoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16bb0a52-15a8-477e-9e9e-1abab4b81fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf2txt(fileName):\n",
    "    \n",
    "    import PyPDF2\n",
    "    import pydoop.hdfs as hdfs\n",
    "\n",
    "    # Utwórz obiekt odnoszący się do przykładowego pliku\n",
    "    pdfFileObj = hdfs.open(fileName, \"rb\") \n",
    "    \n",
    "    # Utwórz obiekt PdfFileReader \n",
    "    pdfReader = PyPDF2.PdfReader(pdfFileObj) \n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    for page in range(len(pdfReader.pages)): \n",
    "        pageObj = pdfReader.pages[page] \n",
    "        content = pageObj.extract_text() \n",
    "        lines.extend(content.splitlines())\n",
    "    pdfFileObj.close()\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa4855-4d78-45e0-913d-dc718fe80953",
   "metadata": {},
   "source": [
    "Sprawdźmy ją. Tym razem będzie to odczyt z systemu plików HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e78789e-551e-4c6e-9fed-0c124abcb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_3gab = pdf2txt(\"cano-pdf/3gab.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d22e0a4-50af-4742-9973-bb38c8b4ee68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['The Adventure of the Three Gables',\n 'Arthur Conan Doyle',\n 'This text is provided to you “as-is” without any warranty. No warranties of any kind, expressed or implied, are made to you as to the']"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_3gab[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74654209-4bde-4733-92c5-2024a160a03b",
   "metadata": {},
   "source": [
    "Pozostało nam z niej skorzystać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aa9be85-d883-442a-a984-7f31aaf73877",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = fileNames.flatMap(lambda fn: pdf2txt(fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5527f274-d2bc-4d7b-9146-7af247785bd2",
   "metadata": {},
   "source": [
    "Próba generalna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c48bcb71-e31a-4be4-9125-2f6e386127d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "                                                                                \r"
    },
    {
     "data": {
      "text/plain": "['The Adventure of the Three Gables', 'Arthur Conan Doyle']"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bffa89-34a8-4ffa-9939-b90aff4249aa",
   "metadata": {},
   "source": [
    "# Zadania \n",
    "\n",
    "Teraz już z górki. Reszta należy do Ciebie. \n",
    "\n",
    "**Uwaga!** Na wynikowym RDD, który powinien zawierać dla każdego słowa liczbę jego wystąpień, będziemy wykonywali wiele operacji. <br>\n",
    "Zadbaj o to, aby każdorazowe użycie tego wynikowego RDD nie powodowało odczytywania plików PDF.\n",
    "\n",
    "## Zadanie 1\n",
    "\n",
    "Utwórz obiekt RDD `wordCounts`, który dla każdego słowa liczbę jego wystąpień."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bf30829-61ca-45a7-872e-184ce15d9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "words = lines.flatMap(lambda line: re.split(r'\\W+', line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ade0971a-5c7b-4ed5-85a4-5d39b9c2f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[Stage 9:=============================>                             (1 + 1) / 2]\r"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('The', 2769)\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "                                                                                \r"
    }
   ],
   "source": [
    "wordCounts = words.groupBy(lambda word: word).map(lambda pair: (pair[0], len(pair[1])))\n",
    "print(wordCounts.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4dcca2-544d-434c-8ed4-ee37120df3a1",
   "metadata": {},
   "source": [
    "## Zadanie 2\n",
    "\n",
    "Znajdź 10 najczęściej wykorzystywanych słów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5255c1e5-f4a2-4d0c-99ff-5276fb55d755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('', 42232),\n ('the', 33333),\n ('I', 17288),\n ('and', 16818),\n ('of', 16688),\n ('to', 16038),\n ('a', 15083),\n ('that', 10693),\n ('in', 10359),\n ('was', 9763)]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounts.sortBy(lambda pair: pair[1], False).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9e916-9b64-4bb1-b869-daa2bed3db76",
   "metadata": {},
   "source": [
    "## Zadanie 3\n",
    "\n",
    "Znajdź 10 najczęściej wykorzystywanych słów, które składają się z co najmniej 5 liter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e67118d-ea7c-4cad-bce3-919449b4456e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('which', 4243),\n ('Holmes', 3044),\n ('there', 2186),\n ('would', 2150),\n ('could', 1843),\n ('should', 1229),\n ('There', 1200),\n ('about', 1096),\n ('before', 1016),\n ('little', 1009)]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounts.filter(lambda pair: len(pair[0])>=5).sortBy(lambda pair: pair[1], False).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87cd2f6-bc5d-4ad7-801c-8f04a99d03a8",
   "metadata": {},
   "source": [
    "## Zadanie 4\n",
    "\n",
    "Ile razy pojawiło się słowo \"Watson\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc241de2-a77c-423d-8b44-9794662c033e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('Watson', 984)]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounts.filter(lambda pair: pair[0] == \"Watson\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8908e8-2b48-42b9-bdbb-59fc70e5080c",
   "metadata": {},
   "source": [
    "## Zadanie 5\n",
    "\n",
    "A ile razy pojawiło się słowo \"Moriarty\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73038949-9869-4a94-9b1e-554e7b998f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('Moriarty', 49)]"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounts.filter(lambda pair: pair[0] == \"Moriarty\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac9331-b528-43eb-b060-aad046732726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
